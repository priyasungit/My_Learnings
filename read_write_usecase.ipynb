{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4584a443-9077-455d-bdec-416fafeb75e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A catalog named telecom_catalog_assign\n",
    "A schema landing_zone\n",
    "A volume landing_vol\n",
    "Using dbutils.fs.mkdirs, create folders:\n",
    "/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/ /Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/ /Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\n",
    "Explain the difference between (Just google and understand why we are going for volume concept for prod ready systems):\n",
    "a. Volume vs DBFS/FileStore\n",
    "## # b. Why production teams prefer Volumes for regulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b0cc858-e640-4cf8-a235-5290659eb12c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS telecom_catalog_assign\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS  telecom_catalog_assign.landing_zone\")\n",
    "spark.sql(\n",
    "    \"CREATE VOLUME if not exists telecom_catalog_assign.landing_zone.landing_vol\"\n",
    ")\n",
    "\n",
    "# Now creat\n",
    "# Then create the directory\n",
    "#dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d79745f-0f7e-4626-a9ef-804f70d31855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_csv = '''\n",
    "101,Arun,31,Chennai,PREPAID\n",
    "102,Meera,45,Bangalore,POSTPAID\n",
    "103,Irfan,29,Hyderabad,PREPAID\n",
    "104,Raj,52,Mumbai,POSTPAID\n",
    "105,,27,Delhi,PREPAID\n",
    "106,Sneha,abc,Pune,PREPAID\n",
    "'''\n",
    "\n",
    "# Define the DBFS path for the new file\n",
    "dbfs_path = \"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customers.csv\" # A common location for user uploads\n",
    "\n",
    "# Use dbutils.fs.put() to write the string content to DBFS\n",
    "# The 'True' argument means 'overwrite' (optional, set to True to replace existing file)\n",
    "dbutils.fs.put(dbfs_path, customer_csv.strip(), True)\n",
    "\n",
    "print(f\"Data successfully written to {dbfs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ce6f6c-6d38-48ca-b328-08d47895b47f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usage_tsv ='''\n",
    "customer_id\\tvoice_mins\\tdata_mb\\tsms_count\n",
    "101\\t320\\t1500\\t20\n",
    "102\\t120\\t4000\\t5\n",
    "103\\t540\\t600\\t52\n",
    "104\\t45\\t200\\t2\n",
    "105\\t0\\t0\\t0\n",
    "'''\n",
    "dbfs_path = \"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage.tsv\"\n",
    "dbutils.fs.put(dbfs_path, usage_tsv.strip(), True)\n",
    "\n",
    "print(f\"Data successfully written to {dbfs_path}\")\n",
    "\n",
    "tower_logs_region1 = '''\n",
    "event_id|customer_id|tower_id|signal_strength|timestamp\n",
    "5001|101|TWR01|-80|2025-01-10 10:21:54\n",
    "'''\n",
    "dbfs_path = \"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region1.csv\"\n",
    "dbutils.fs.put(dbfs_path, tower_logs_region1.strip(), True)\n",
    "\n",
    "print(f\"Data successfully written to {dbfs_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19f08364-e914-4715-b416-3a1466946f1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer\")\n",
    "dbutils.fs.ls(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage\")\n",
    "dbutils.fs.ls(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb8436e6-84fd-47e6-9e6b-8c1c52fbc58c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tower_logs_region2 = '''\n",
    "event_id|customer_id|tower_id|signal_strength|timestamp\n",
    "5004|104|TWR05|-75|2025-01-10 11:01:12\n",
    "'''\n",
    "dbfs_path = \"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region2.csv\"\n",
    "dbutils.fs.put(dbfs_path, tower_logs_region2.strip(), True)\n",
    "\n",
    "print(f\"Data successfully written to {dbfs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5322ad-6fc6-48ff-8c58-04f03a551348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Read all tower logs using: Path glob filter (example: *.csv) Multiple paths input Recursive lookup\n",
    "\n",
    "Demonstrate these 3 reads separately: Using pathGlobFilter Using list of paths in spark.read.csv([path1, path2]) Using .option(\"recursiveFileLookup\",\"true\")\n",
    "\n",
    "Compare the outputs and understand when each should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c648adf3-99d4-47e9-9ed6-bb0522af074d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_multiple_sources=spark.read.csv(path=[\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region1.csv\",\"dbfs:////Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region2.csv\"],inferSchema=True,header=True,sep='|',pathGlobFilter=\"*.csv\",recursiveFileLookup=True)\n",
    "#.toDF(\"cid\",\"fn\",\"ln\",\"a\",\"p\")\n",
    "print(df_multiple_sources.count())\n",
    "df_multiple_sources.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00e27f40-9a8c-4c56-9deb-5a45b19e80aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''Demonstrate these 3 reads separately: Using pathGlobFilter Using list of paths in spark.read.csv([path1, path2]) Using .option(\"recursiveFileLookup\",\"true\")'''\n",
    "df_multiple_sources=spark.read.csv(path=[\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region1.csv\",\"dbfs:////Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region2.csv\"],inferSchema=True,header=True,sep='|',recursiveFileLookup=True)\n",
    "print(df_multiple_sources.count())\n",
    "df_multiple_sources.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc7ad0b-0482-43ee-8a06-a4c5cf1154be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "csv_df1=spark.read.csv(path=\"dbfs:////Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/tower_logs_region*.csv\",inferSchema=True,header=True,sep='|')\n",
    "print(csv_df1.count())\n",
    "csv_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43812701-3c58-4de9-84f8-8bd1cbb7a75f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_df1=spark.read.csv(path=\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customers.csv\",inferSchema=False,header=False,sep=',').toDF(\"id\",\"name\",\"age\",\"loc\",\"plan\")\n",
    "df2=csv_df1.where(\"age!='abc' \")\n",
    "csv_df1.printSchema()\n",
    "print(csv_df1.count())\n",
    "csv_df1.show()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a0ca274-f3d8-4763-9134-6549892d9b8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_df1=spark.read.csv(path=\"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage.tsv\",inferSchema=True,header=True,sep='\\t')\n",
    "print(csv_df1.count())\n",
    "csv_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7495fadd-07c8-4e11-a416-c47c0ada841a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_recursive = spark.read.format(\"csv\") .option(\"header\", \"true\") .option(\"delimiter\", \"|\") .option(\"recursiveFileLookup\", \"true\") .load(\"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\")\n",
    "\n",
    "print(\"--- DataFrame using recursiveFileLookup='true' ---\")\n",
    "df_recursive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47b527c6-5da0-4b84-9957-01fd7697ed60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_glob = spark.read.format(\"csv\") .option(\"header\", \"true\")  .option(\"delimiter\", \"|\") .option(\"pathGlobFilter\", \"*region*.csv\") .load(\"dbfs:/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\")\n",
    "\n",
    "print(\"--- DataFrame using pathGlobFilter ('region*.csv') ---\")\n",
    "df_glob.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db64b6d9-4e99-470e-9666-cb19d8d34f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Apply column names using string using toDF function for customer data\n",
    "Apply column names and datatype using the schema function for usage data\n",
    "Apply column names and datatype using the StructType with IntegerType, StringType, TimestampType and other classes for towers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cffc810-5238-41f6-a599-b86e13a7422a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#customer_id|voice_mins|data_mb|sms_count\n",
    "str_struct=\"customer_id integer,voice_mins integer,data_mb integer,sms_count integer\"\n",
    "csv_df1=spark.read.schema(str_struct).csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage.tsv\",header=True,sep='\\t')\n",
    "print(csv_df1.printSchema())\n",
    "csv_df1.show()\n",
    "\n",
    "\n",
    "#2. Important part - Using structure type to define custom complex schema.\n",
    "#4000001,Kristina,Chung,55,Pilot\n",
    "#pattern - \n",
    "#import the types library based classes..\n",
    "# define_structure=StructType([StructField(\"colname\",DataType(),True),StructField(\"colname\",DataType(),True)...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5455794-b506-4cd4-9300-0b39f32d4626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#event_id|customer_id|tower_id|signal_strength|          timestamp\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "custom_schema=StructType([StructField(\"event_id\",IntegerType(),False),StructField(\"customer_id\",IntegerType(),False),StructField(\"tower_id\",StringType(),False),StructField(\"signal_strength\",IntegerType(),False),StructField(\"timestamp\",StringType(),False)])\n",
    "csv_df1=spark.read.schema(custom_schema).csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\",pathGlobFilter=\"*.csv\",header='True',sep='|')\n",
    "print(csv_df1.printSchema())\n",
    "csv_df1.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "read_write_usecase",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
